#!/usr/bin/octave -qfif (nargin!=1)printf("Usage: multinomial.m <data_filename>");exit(1);endarglist=argv();datafile=arglist{1};disp("Loading data...");load(datafile);disp("Data load complete.");[nrows,ncols]=size(data);rand("seed",23); perm=randperm(nrows);pdata=data(perm,:); #utilizamos los indices  para sacar la permutacion de los datostrper=0.9;ntr=floor(nrows*trper); #numero de muestras trainnte=nrows-ntr; #numero de muestras testtr=pdata(1:ntr,:);  #traintrData = tr(:,1:ncols-1); #matriz trainDatatrLabels = tr(:,ncols); #vector de clases trainingHam = find(trLabels ==  0);  #vectores HAMSpam = find(trLabels ==  1); #vectores SPAMte=pdata(ntr+1:end,:); #testtestData = te(:,1:ncols-1); #matriz testDatatestLabels = te(:,ncols); #vector de clases test#Calculamos las prioris realizando un conteoPrioriHam = length(Ham)/length(trLabels); #Probabilidad a priori de HAM MuestrasHam/MuestrasTotalesPrioriSpam = length(Spam)/length(trLabels); #Probabilidad a priori de SPAM MuestrasSpam/MuestrasTotalessumDataHam = sum(sum(trData(Ham,:))); pHam = sum(trData(Ham,:)) / sumDataHam; #prototipo de HAMsumDataSpam = sum(sum(trData(Spam,:))); pSpam = sum(trData(Spam,:)) / sumDataSpam; #Prototipo de SPAMgH = log(pHam)*testData' +log(PrioriHam); #funciones discriminantes para HamgS = log(pSpam)*testData' +log(PrioriSpam); #funciones discriminantes para SPAMt = gH < gS; #1 si HAM < SPAM --> Se clasifica en SPAMcorrect = testLabels == t'; #vector con los correctos es decir predicci√≥n igual a las etiquetas de testacierto = sum(correct==1)/numel(testLabels); #probabilidad de aciertoprintf("%.3f",1-acierto)